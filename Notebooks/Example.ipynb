{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca2420e6",
   "metadata": {},
   "source": [
    "# Download the repo from https://github.com/AdhyaSuman/CTMKD and run the setup file to install OCTIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6863e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T06:05:13.301759Z",
     "start_time": "2023-02-02T06:05:13.296055Z"
    }
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01b462c",
   "metadata": {},
   "source": [
    "Run the setup.py file using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b78d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T06:05:17.906036Z",
     "start_time": "2023-02-02T06:05:13.692768Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e01abc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T06:05:19.125488Z",
     "start_time": "2023-02-02T06:05:17.913335Z"
    }
   },
   "outputs": [],
   "source": [
    "from octis.dataset.dataset import Dataset\n",
    "\n",
    "#import models\n",
    "from octis.models.LDA import LDA\n",
    "from octis.models.ETM import ETM\n",
    "from octis.models.ProdLDA import ProdLDA\n",
    "from octis.models.NeuralLDA import NeuralLDA\n",
    "from octis.models.CTM import CTM\n",
    "from octis.models.CTMKD import CTMKD\n",
    "\n",
    "#Import coherence metrics:\n",
    "from octis.evaluation_metrics.coherence_metrics import *\n",
    "\n",
    "import random, torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559f633",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e2d408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T06:05:19.132289Z",
     "start_time": "2023-02-02T06:05:19.126695Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data_dir = './preprocessed_datasets'\n",
    "\n",
    "\n",
    "def get_dataset(dataset_name):\n",
    "    data = Dataset()\n",
    "    if dataset_name=='20NG':\n",
    "        data.fetch_dataset(\"20NewsGroup\")\n",
    "    elif dataset_name=='M10':\n",
    "        data.load_custom_dataset_from_folder(data_dir + \"/M10\")\n",
    "    else:\n",
    "        raise Exception('Missing Dataset name...!!!')\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def get_model(model_name, num_topics, dataset_name, ctm_T=None, num_epochs=100,\n",
    "              KD_epochs=100, num_layers=1, alpha=None, temp=None, seed=None):\n",
    "    \n",
    "    T_BERT = \"paraphrase-distilroberta-base-v2\" \n",
    "    S_BERT = \"all-MiniLM-L6-v2\"\n",
    "    \n",
    "    \n",
    "    if model_name=='LDA':\n",
    "        model = LDA(num_topics=num_topics, random_state=seed, passes=5, use_partitions=False)\n",
    "    \n",
    "    elif model_name=='ETM':\n",
    "        model = ETM(num_topics=num_topics, train_embeddings=True, use_partitions=False)\n",
    "    \n",
    "    elif model_name=='NeuralLDA':\n",
    "        model = NeuralLDA(num_topics=num_topics, use_partitions=False)\n",
    "    \n",
    "    elif model_name=='ProdLDA':\n",
    "        model = ProdLDA(num_topics=num_topics, use_partitions=False)\n",
    "    \n",
    "    \n",
    "    elif model_name=='Student':\n",
    "        model = CTM(num_topics=num_topics,\n",
    "                    hidden_sizes=None,\n",
    "                    dropout=0.2,\n",
    "                    bert_path='./bert/{}_{}'.format(S_BERT, dataset_name),\n",
    "                    bert_model=S_BERT,\n",
    "                    num_epochs=num_epochs,\n",
    "                    inference_type=\"zeroshot\",\n",
    "                    use_partitions=False, use_validation=False\n",
    "                   )\n",
    "        \n",
    "    elif model_name=='CTM_KD_2wd_woPartition':\n",
    "        model = CTMKD(num_topics=num_topics,\n",
    "                       inference_type=\"zeroshot\",\n",
    "                       dropout=0.2,\n",
    "                       num_epochs=num_epochs,\n",
    "                       pre_processing_type='KD',\n",
    "                       hidden_sizes=None,\n",
    "                       student_bert_path='./bert/{}_{}'.format(S_BERT, dataset_name),\n",
    "                       teacher_bert_path='./bert/{}_{}'.format(T_BERT, dataset_name),\n",
    "                       student_bert_model=S_BERT,\n",
    "                       teacher_bert_model=T_BERT,\n",
    "                       teacher=ctm_T,\n",
    "                       use_partitions=False, use_validation=False,\n",
    "                       KD_epochs=KD_epochs,\n",
    "                       alpha=alpha,\n",
    "                       temp=temp,\n",
    "                       KD_loss_type='2wd',\n",
    "                       use_mean_logvar_recon_kd=True\n",
    "                      )\n",
    "    \n",
    "    elif model_name=='CTM_Teacher':\n",
    "        model = CTMKD(num_topics=num_topics,\n",
    "                       inference_type=\"combined\",\n",
    "                       num_epochs=num_epochs,\n",
    "                       dropout=0.2,\n",
    "                       pre_processing_type='Teacher_only',\n",
    "                       num_neurons=100,\n",
    "                       num_layers=num_layers,\n",
    "                       student_bert_path='./bert/{}_{}'.format(S_BERT, dataset_name),\n",
    "                       teacher_bert_path='./bert/{}_{}'.format(T_BERT, dataset_name),\n",
    "                       student_bert_model=S_BERT,\n",
    "                       teacher_bert_model=T_BERT,\n",
    "                       teacher=ctm_T,\n",
    "                       use_partitions=False, use_validation=False\n",
    "                       )\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2fbb1d",
   "metadata": {},
   "source": [
    "# Run Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554050f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T05:57:19.410875Z",
     "start_time": "2023-02-02T05:51:12.344327Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "n_topics = [20, 50, 100]\n",
    "models = ['CTM_Teacher']\n",
    "datasets = ['20NG']\n",
    "\n",
    "T_Layer = {\n",
    "    '20NG':{\n",
    "        20:1,\n",
    "        50:1,\n",
    "        100:5\n",
    "    },\n",
    "    'M10':{\n",
    "        10:4,\n",
    "        20:5,\n",
    "        50:2,\n",
    "        100:3\n",
    "    }\n",
    "}\n",
    "\n",
    "results = {\n",
    "    'Dataset': [],\n",
    "    'K': [],\n",
    "    'Model':[],\n",
    "    'NPMI':[],\n",
    "    'CV': [],\n",
    "}\n",
    "\n",
    "\n",
    "for d in datasets:\n",
    "    data = get_dataset(d)\n",
    "    \n",
    "    npmi = Coherence(texts=data.get_corpus(), measure='c_npmi')\n",
    "    cv = Coherence(texts=data.get_corpus(), measure='c_v')\n",
    "    \n",
    "    for m in models:\n",
    "        for k in n_topics:\n",
    "            print(\"-\"*100)\n",
    "            print('Dataset:{},\\t Model:{},\\t K={}'.format(d, m, k))\n",
    "            print(\"-\"*100)\n",
    "\n",
    "            model = get_model(model_name=m, num_topics=k, dataset_name=d, num_layers=T_Layer[d][k])\n",
    "            output = model.train_model(dataset=data, save_dir='./Teacher_models/{}/'.format(d))\n",
    "            \n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            #params:\n",
    "            results['Dataset'].append(d)\n",
    "            results['Model'].append(m)\n",
    "            results['K'].append(k)\n",
    "\n",
    "            #Coherence Scores:\n",
    "            results['NPMI'].append(npmi.score(output))\n",
    "            results['CV'].append(cv.score(output))\n",
    "\n",
    "            print('Results:-\\n', results)\n",
    "            print('#'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc00a54e",
   "metadata": {},
   "source": [
    "# Run S and SKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610e9ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T06:17:01.113105Z",
     "start_time": "2023-02-02T06:05:25.384587Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from octis.models.contextualized_topic_models_KD.models import ctmkd\n",
    "from os import listdir\n",
    "from random import seed, randint\n",
    "from IPython.display import clear_output\n",
    "\n",
    "seeds = [randint(0, 2e3) for _ in range(5)]\n",
    "n_topics = [20, 50, 100]\n",
    "models = ['LDA', 'ETM', 'NeuralLDA', 'ProdLDA', 'Student', 'CTM_KD_2wd_woPartition']\n",
    "datasets = ['20NG']\n",
    "\n",
    "\n",
    "SKD_hyp = {\n",
    "    '20NG':{\n",
    "        20: {\n",
    "            'alpha': 0.1,\n",
    "            'temp': 3.0\n",
    "            },\n",
    "        \n",
    "        50: {\n",
    "            'alpha': 0.9,\n",
    "            'temp': 3.0\n",
    "            },\n",
    "        \n",
    "        100: {\n",
    "            'alpha': 0.9,\n",
    "            'temp': 5.0\n",
    "            },\n",
    "    },\n",
    "        \n",
    "    'M10':{\n",
    "        10: {\n",
    "            'alpha': 0.6,\n",
    "            'temp': 2.0\n",
    "            },\n",
    "        \n",
    "        20: {\n",
    "            'alpha': 0.8,\n",
    "            'temp': 4.0\n",
    "            },\n",
    "        \n",
    "        50: {\n",
    "            'alpha': 0.8,\n",
    "            'temp': 1.0\n",
    "            },\n",
    "        \n",
    "        100: {\n",
    "            'alpha': 0.9,\n",
    "            'temp': 4.0\n",
    "            }\n",
    "    }\n",
    "}\n",
    "\n",
    "T_Layer = {\n",
    "    '20NG':{\n",
    "        20:'(100,)',\n",
    "        50:'(100,)',\n",
    "        100:'(100, 100, 100, 100, 100)'\n",
    "    },\n",
    "    'M10':{\n",
    "        10:'(100, 100, 100, 100)',\n",
    "        20:'(100, 100, 100, 100, 100)',\n",
    "        50:'(100, 100)',\n",
    "        100:'(100, 100, 100)',\n",
    "    }\n",
    "}\n",
    "\n",
    "results = {\n",
    "    'Dataset': [],\n",
    "    'Seed': [],\n",
    "    'K': [],\n",
    "    'Model':[],\n",
    "    'NPMI':[],\n",
    "    'CV': []\n",
    "}\n",
    "\n",
    "for d in datasets:\n",
    "    data = get_dataset(d)\n",
    "    \n",
    "    npmi = Coherence(texts=data.get_corpus(), measure='c_npmi', topk=10)\n",
    "    cv = Coherence(texts=data.get_corpus(), measure='c_v', topk=10)\n",
    "    \n",
    "    for m in models:\n",
    "        for k in n_topics:\n",
    "            for seed in seeds:\n",
    "#                 clear_output(wait=False)\n",
    "                print(\"-\"*100)\n",
    "                print('Dataset:{},\\t Model:{},\\t K={},\\t seed={}'.format(d, m, k, seed))\n",
    "                print(\"-\"*100)\n",
    "                \n",
    "                random.seed(seed)\n",
    "                torch.random.manual_seed(seed)\n",
    "                \n",
    "                ctm_T=None\n",
    "                alpha=None\n",
    "                temp=None\n",
    "                if m in ['CTM_KD_2wd_woPartition']:\n",
    "                    SAVE_DIR = './Teacher_models/{}/AVITM_nc_{}_tpm_0.0_tpv_{}_hs_prodLDA_ac_{}_do_softplus_lr_0.2_mo_0.002_rp_0.99'.format(d, k, 1 - (1./k), T_Layer[d][k])\n",
    "                    epoch = ''.join(x for x in listdir(SAVE_DIR)[0] if x.isdigit())\n",
    "                    ctm_T=ctmkd.CTMKD(input_size=len(data.get_vocabulary()), bert_input_size=768)\n",
    "                    print('Loading Teacher Model for, model={}, #Topics={}'.format(m, k))\n",
    "                    ctm_T.load(SAVE_DIR, epoch=epoch)\n",
    "                    alpha = SKD_hyp[d][k]['alpha']\n",
    "                    temp=SKD_hyp[d][k]['temp']\n",
    "                \n",
    "                model = get_model(model_name=m,\n",
    "                                  num_topics=k,\n",
    "                                  dataset_name=d,\n",
    "                                  ctm_T=ctm_T, \n",
    "                                  alpha=alpha, \n",
    "                                  temp=temp,\n",
    "                                  seed=seed)\n",
    "                \n",
    "                output = model.train_model(dataset=data)\n",
    "                \n",
    "                del model\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                #Hyperparams:\n",
    "                results['Dataset'].append(d)\n",
    "                results['Model'].append(m)\n",
    "                results['K'].append(k)\n",
    "                results['Seed'].append(seed)\n",
    "                \n",
    "                #############\n",
    "\n",
    "                #Coherence Scores:\n",
    "                results['NPMI'].append(npmi.score(output))\n",
    "                results['CV'].append(cv.score(output))\n",
    "                \n",
    "                print('Results:-\\n', results)\n",
    "                print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7973b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
